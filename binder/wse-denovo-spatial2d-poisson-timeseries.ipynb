{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import downstream\n",
    "import imageio\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from teeplot import teeplot as tp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pylib.munge._addend_groups import addend_groups\n",
    "from pylib.munge._union_upsample import union_upsample\n",
    "from pylib.munge._squeeze import squeeze_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -diwmuv -iv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teeplot_subdir = \"wse-denovo-spatial2d-poisson-timeseries\"\n",
    "teeplot_subdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxs = pl.from_pandas(\n",
    "    pd.read_parquet(\"https://osf.io/cq7zd/download\"),\n",
    ").with_row_index(\n",
    "    \"dstream_data_id\",\n",
    ")\n",
    "display(dfxs.describe()), display(dfxs.head()), display(dfxs.tail());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_logger_timeseries_data(df: pl.DataFrame) -> pl.DataFrame:\n",
    "\n",
    "    # sample every 64th tile\n",
    "    df = df.filter((pl.col(\"col\") % 8 == 0) & (pl.col(\"row\") % 8 == 0))\n",
    "\n",
    "    # unpack dstream data items from logger hex strings\n",
    "    dfu = downstream.dataframe.unpack_data_packed(df)\n",
    "    df = downstream.dataframe.explode_lookup_unpacked(\n",
    "        dfu.with_columns(\n",
    "            # fast forward loggers to at least dstream_S entries\n",
    "            # (i.e., buffer filled)\n",
    "            # these will be semantically-correct zero values\n",
    "            dstream_T=pl.max_horizontal(\n",
    "                pl.col(\"dstream_T\"), pl.col(\"dstream_S\")\n",
    "            ),\n",
    "        ),\n",
    "        value_type=\"uint8\",\n",
    "    )\n",
    "\n",
    "    # join metadata onto unpacked data\n",
    "    df = df.join(\n",
    "        dfu.select(\n",
    "            \"dstream_data_id\",\n",
    "            \"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\",\n",
    "            \"CEREBRASLIB_TRAITLOGGER_DILATION\",\n",
    "            \"col\",\n",
    "            \"replicate\",\n",
    "            \"row\",\n",
    "            \"tile\",\n",
    "        ),\n",
    "        on=\"dstream_data_id\",\n",
    "    )\n",
    "\n",
    "    # apply dilation to dstream_T and dstream_Tbar\n",
    "    df = df.with_columns(\n",
    "        dstream_T=pl.col(\"dstream_T\")\n",
    "        * pl.col(\"CEREBRASLIB_TRAITLOGGER_DILATION\"),\n",
    "        dstream_Tbar=pl.col(\"dstream_Tbar\")\n",
    "        * pl.col(\"CEREBRASLIB_TRAITLOGGER_DILATION\"),\n",
    "    )\n",
    "\n",
    "    # addend time time series groups with final zero value entry\n",
    "    df = addend_groups(\n",
    "        df,\n",
    "        group_by=[\"replicate\", \"tile\"],\n",
    "        aggs=(\n",
    "            pl.col(\"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\")\n",
    "            .unique()\n",
    "            .pipe(squeeze_int),\n",
    "            pl.col(\"col\").unique().pipe(squeeze_int),\n",
    "            (pl.col(\"dstream_Tbar\") + 1).max().alias(\"dstream_Tbar\"),\n",
    "            pl.lit(0).alias(\"dstream_value\"),\n",
    "            pl.col(\"row\").unique().pipe(squeeze_int),\n",
    "        ),\n",
    "        inner_only=True,\n",
    "    )\n",
    "\n",
    "    # upsample to fill in dstream_Tbar dropped by some loggers\n",
    "    # prevents ampling biases from longer-running vs shorter-running loggers\n",
    "    df = union_upsample(\n",
    "        df,\n",
    "        upsample=\"dstream_Tbar\",\n",
    "        group_by=\"tile\",\n",
    "        fill_null_ops=[\n",
    "            (pl.all(), {\"strategy\": \"forward\"}),\n",
    "            (pl.all(), {\"strategy\": \"zero\"}),\n",
    "        ],\n",
    "    )\n",
    "    assert len(df[\"dstream_Tbar\"].value_counts()[\"count\"].unique()) == 1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for _, df in tqdm(dfxs.group_by(\"replicate\")):\n",
    "    df = unpack_logger_timeseries_data(df)\n",
    "    res.append(df)\n",
    "\n",
    "df = pl.concat(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean of dstream_value at each dstream_Tbar across tiles\n",
    "df_mean = df.group_by(\"replicate\", \"dstream_Tbar\").agg(\n",
    "    pl.col(\"dstream_value\").mean(),\n",
    "    pl.col(\"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\")\n",
    "    .unique()\n",
    "    .pipe(squeeze_int),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tp.teed(\n",
    "    sns.relplot,\n",
    "    data=df_mean.with_columns(\n",
    "        pl.col(\"replicate\")\n",
    "        .rank(method=\"dense\")\n",
    "        .over(\"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\")\n",
    "        .cast(pl.Int32)\n",
    "        .alias(\"replicate number\")\n",
    "    ),\n",
    "    x=\"dstream_Tbar\",\n",
    "    y=\"dstream_value\",\n",
    "    hue=\"replicate\",\n",
    "    col=\"replicate number\",\n",
    "    row=\"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\",\n",
    "    alpha=0.5,\n",
    "    aspect=1.5,\n",
    "    errorbar=None,\n",
    "    height=1.2,\n",
    "    linewidth=1,\n",
    "    legend=False,\n",
    "    kind=\"line\",\n",
    "    marker=\"d\",\n",
    "    markersize=4,\n",
    "    markers=True,\n",
    "    facet_kws=dict(margin_titles=True),\n",
    "    teeplot_subdir=teeplot_subdir,\n",
    "    teeplot_outexclude=[\"marker\"],\n",
    ") as g:\n",
    "    g.set(xlim=(10, 80000))\n",
    "    g.set(ylim=(0.00001, 2))\n",
    "    g.set_titles(\n",
    "        col_template=\"\",\n",
    "        row_template=\"{row_name} Avail\\nBen Muts\",\n",
    "    )\n",
    "    g.set_axis_labels(x_var=\"Generations\", y_var=\"Normomut\\nPrevalence\")\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axhline(1, ls=\"--\", color=\"black\", linewidth=1, zorder=-10)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(teeplot_subdir, exist_ok=True)\n",
    "\n",
    "for (replicate, nmut), dfr in tqdm(\n",
    "    df.group_by(\"replicate\", \"CEREBRASLIB_HYPERMUT_NUM_AVAIL_BEN_MUTS\"),\n",
    "):\n",
    "    frames = []\n",
    "    for (dstream_Tbar,), dff in dfr.sort(\"dstream_Tbar\").group_by(\n",
    "        \"dstream_Tbar\", maintain_order=True\n",
    "    ):\n",
    "\n",
    "        dff = dff.with_columns(\n",
    "            col_rank=pl.col(\"col\").rank(method=\"dense\").cast(pl.Int32) - 1,\n",
    "            row_rank=pl.col(\"row\").rank(method=\"dense\").cast(pl.Int32) - 1,\n",
    "        )\n",
    "\n",
    "        num_rows = dff[\"row_rank\"].max() + 1\n",
    "        num_cols = dff[\"col_rank\"].max() + 1\n",
    "\n",
    "        frame = np.empty((num_rows, num_cols), dtype=np.uint8)\n",
    "        frame[dff[\"row_rank\"], dff[\"col_rank\"]] = dff[\"dstream_value\"] * 255\n",
    "        frame = np.kron(frame, np.ones((4, 4), dtype=frame.dtype))\n",
    "        frames.append(frame)\n",
    "\n",
    "        outdir = f\"{teeplot_subdir}/a=traitframes+nmut={nmut}+rep={replicate}\"\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        outpath = f\"{outdir}/dstream_Tbar={dstream_Tbar:06}+ext=.png\"\n",
    "        imageio.imwrite(outpath, frame.T)\n",
    "\n",
    "    print(len(frames))\n",
    "    outpath = f\"{teeplot_subdir}/a=traits+nmut={nmut}+rep={replicate}+ext=.gif\"\n",
    "    imageio.mimsave(outpath, frames, duration=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
